{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbodro8Fpmwr",
        "colab_type": "text"
      },
      "source": [
        "# **What is BERT?**\n",
        "\n",
        "BERT (introduced in [this paper](https://arxiv.org/abs/1810.04805)) stands for Bidirectional Encoder Representations from Transformers. \n",
        "\n",
        "- Bidirectional - to understand the text  you're looking you'll have to look back (at the previous words) and forward (at the next words)\n",
        "- Transformers - The [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper presented the Transformer model. The Transformer reads entire sequences of tokens at once. In a sense, the model is non-directional, while LSTMs read sequentially (left-to-right or right-to-left). The attention mechanism allows for learning contextual relations between words (e.g. `his` in a sentence refers to Jim).\n",
        "- (Pre-trained) contextualized word embeddings - [The ELMO paper](https://arxiv.org/abs/1802.05365v2) introduced a way to encode words based on their meaning/context. Nails has multiple meanings - fingernails and metal nails.\n",
        "\n",
        "BERT was trained by masking 15% of the tokens with the goal to guess them. An additional objective was to predict the next sentence. Let's look at examples of these tasks:\n",
        "\n",
        "### Masked Language Modeling (Masked LM)\n",
        "\n",
        "The objective of this task is to guess the masked tokens. Let's look at an example, and try to not make it harder than it has to be:\n",
        "\n",
        "That's `[mask]` she `[mask]` -> That's what she said\n",
        "\n",
        "### Next Sentence Prediction (NSP)\n",
        "\n",
        "Given a pair of two sentences, the task is to say whether or not the second follows the first (binary classification). Let's continue with the example:\n",
        "\n",
        "*Input* = `[CLS]` That's `[mask]` she `[mask]`. [SEP] Hahaha, nice! [SEP]\n",
        "\n",
        "*Label* = *IsNext*\n",
        "\n",
        "*Input* = `[CLS]` That's `[mask]` she `[mask]`. [SEP] Dwight, you ignorant `[mask]`! [SEP]\n",
        "\n",
        "*Label* = *NotNext*\n",
        "\n",
        "The training corpus was comprised of two entries: [Toronto Book Corpus](https://arxiv.org/abs/1506.06724) (800M words) and English Wikipedia (2,500M words). While the original Transformer has an encoder (for reading the input) and a decoder (that makes the prediction), BERT uses only the decoder.\n",
        "\n",
        "BERT is simply a pre-trained stack of Transformer Encoders. How many Encoders? We have two versions - with 12 (BERT base) and 24 (BERT Large).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We'll need [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMy3RgVPt5Bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -qq transformers;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4fL5T7iMK5",
        "colab_type": "text"
      },
      "source": [
        "Let's also download the scraped data from  google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl8udL55O9gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV;\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VJf2Fp9glAd",
        "colab_type": "text"
      },
      "source": [
        "# Data Exploration\n",
        "We'll load the Google Play app reviews dataset, that we've put together in the previous part:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gibBxMEPxiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtVRVwUQrGpL",
        "colab_type": "text"
      },
      "source": [
        "Lets see some infomation about the columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNraolUgPyK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPu_j6bwwM8k",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQwPhI0jQJWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 8, 6\n",
        "\n",
        "sns.countplot(df.score)\n",
        "plt.xlabel('Review Score');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3epV1olrcOg",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is hugely imbalanced, but it's okay. We're going to convert the dataset into negative, neutral and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNTUV1O_QiR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2: return 0\n",
        "  elif rating == 3: return 1\n",
        "  elif rating >= 4: return 2\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-3GGpopTIbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqSskVWkT_xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_name = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "ax = sns.countplot(df.sentiment);\n",
        "plt.xlabel('Sentiment Score');\n",
        "ax.set_xticklabels(class_name);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pP_O28Krg00",
        "colab_type": "text"
      },
      "source": [
        "Okay now our dataset is properly balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tyGoGNUv2Fm",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "We  already know that Machine Learning models don't work with raw text. You need to convert text to numbers (of some sort). BERT requires even more attention. Here are the requirements: \n",
        "\n",
        "- Add special tokens to separate sentences and do classification\n",
        "- Pass sequences of constant length (introduce padding)\n",
        "- Create array of 0s (pad token) and 1s (real token) called *attention mask*\n",
        "\n",
        "Luckly the Transformers library provides  a wide variety of Transformer models (including BERT). It works with TensorFlow and PyTorch! It also includes prebuild tokenizers that do the heavy lifting for us!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtbK9uofhPWD",
        "colab_type": "text"
      },
      "source": [
        "There is cased and uncased version of BERT. The cased version works better. Intuitively, that makes sense, since \"BAD\" might convey more sentiment than \"bad\".\n",
        "\n",
        "Let's load a pre-trained [BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxpvybjOZ8Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'  \n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zVp-xMrhumX",
        "colab_type": "text"
      },
      "source": [
        "We'll use this text to understand the tokenization process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UUyq50cxZZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_txt = 'When was I last outside? I am stuck at home for 2 months.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzp_c9cRhzf3",
        "colab_type": "text"
      },
      "source": [
        "Some basic operations can convert the text to tokens and tokens to unique integers (ids):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B4TycObDCjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xn6tPspDGNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_we2mw6fEiaQ",
        "colab_type": "text"
      },
      "source": [
        "## Special Tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8KzMkVh4zJ",
        "colab_type": "text"
      },
      "source": [
        "[SEP] - marker for ending of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL02mhJgD9zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RDiAni_h6l9",
        "colab_type": "text"
      },
      "source": [
        "[CLS] - we must add this token to the start of each sentence, so BERT knows we're doing classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsU_ajyhFRTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0NuL86DiffW",
        "colab_type": "text"
      },
      "source": [
        "There is also a special token for padding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGv3Au_BFWeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.pad_token, tokenizer.pad_token_id\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEV7HGKciiqw",
        "colab_type": "text"
      },
      "source": [
        "BERT understands tokens that were in the training set. Everything else can be encoded using the [UNK] (unknown) token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0mZ3tl1FXAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.unk_token, tokenizer.unk_token_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU",
        "colab_type": "text"
      },
      "source": [
        "All of that work can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZv5qsnFYbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "    sample_txt,\n",
        "    max_length = 32,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=False,\n",
        "    pad_to_max_length=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',\n",
        ")\n",
        "\n",
        "encoding.keys()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He6TnFdli2fJ",
        "colab_type": "text"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGHyq9mnGlMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(encoding['input_ids'])\n",
        "encoding['input_ids'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEUx3asajHA5",
        "colab_type": "text"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQRVzQ-VjMX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBKIkRN8jTQW",
        "colab_type": "text"
      },
      "source": [
        "We can inverse the tokenization to have a look at the special tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lntnEt-FjThT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1xGc67CJvaK",
        "colab_type": "text"
      },
      "source": [
        "# Choosing Sequence Length\n",
        "BERT works with fixed-length sequences. We'll use a simple strategy to choose the max length. Let's store the token length of each review:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxDSb_4-GPJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df.content:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLd_M7jdKGum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRVOpCEtKksQ",
        "colab_type": "text"
      },
      "source": [
        "So here is a plot the distribution:\n",
        "\n",
        "Most of the reviews seem to contain less than 128 tokens, so  a maximum length of 128 should be fine.\n",
        "\n",
        "Note: Bigger token size means slower traing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Gv210ukHWK",
        "colab_type": "text"
      },
      "source": [
        "Now I am building a class that takes reviews, targets, tokenizer, max length encodes it's returns the encoded data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoY1xrQQKO6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPReviewDataset(Dataset):\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "                review,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.max_len,\n",
        "                return_token_type_ids=False,\n",
        "                pad_to_max_length=True,\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt',\n",
        "                )\n",
        "    \n",
        "    return {\n",
        "    'review_text': review,\n",
        "    'input_ids': encoding['input_ids'].flatten(),\n",
        "    'attention_mask': encoding['attention_mask'].flatten(),\n",
        "    'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4A3qcTskxS5",
        "colab_type": "text"
      },
      "source": [
        "Some basic hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZkXyQWrL2O5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 20\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzqTuBhKkD4Z",
        "colab_type": "text"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1SdFpmaNpOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(\n",
        "  df,\n",
        "  test_size=0.1,\n",
        "  random_state=RANDOM_SEED\n",
        ")\n",
        "df_val, df_test = train_test_split(\n",
        "  df_test,\n",
        "  test_size=0.5,\n",
        "  random_state=RANDOM_SEED\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5xd2CBZNzT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idQf8T--Nzxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMM5V0XZRGeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0NqY02wuALr",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IxlERRaRL7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7ZdS7nPRpUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_wdPL6mSQfT",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Classification with BERT and Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBJq3S_-uIh4",
        "colab_type": "text"
      },
      "source": [
        "Loading a pretrained BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xHdRHGJRueD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6AjZtHUuX4U",
        "colab_type": "text"
      },
      "source": [
        "And try to use it on the encoding of our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "actAaDkMUvOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "input_ids=encoding['input_ids'],\n",
        "attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV",
        "colab_type": "text"
      },
      "source": [
        "The `last_hidden_state` is a sequence of hidden states of the last layer of the model. Obtaining the `pooled_output` is done by applying the [BertPooler](https://github.com/huggingface/transformers/blob/edf0582c0be87b60f94f41c659ea779876efc7be/src/transformers/modeling_bert.py#L426) on `last_hidden_state`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5zi8h6yUwHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4dAot4zbz8k",
        "colab_type": "text"
      },
      "source": [
        "We have the hidden state for each of our 32 tokens (the length of our example sequence). But why 768? This is the number of hidden units in the feedforward-networks. We can verify that by checking the config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jgqCpVPU0-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model.config.hidden_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTKi8-rTd_j4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "You can think of the `pooled_output` as a summary of the content, according to BERT. Albeit, you might try and do better. Let's look at the shape of the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDwUNgueVEvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pooled_output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf",
        "colab_type": "text"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P81U1hsnVhBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LudXdylUWnWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc",
        "colab_type": "text"
      },
      "source": [
        "Our classifier delegates most of the heavy lifting to the BertModel. We use a dropout layer for some regularization and a fully-connected layer for our output. Note that we're returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work.\n",
        "\n",
        "This should work like any other PyTorch model. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3tu-AUpYh9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SentimentClassifier(len(class_name))\n",
        "model = model.to(device)\n",
        "\n",
        "EPOCHS = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG8xekyQZpUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "  def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "      for d in data_loader:\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        targets = d[\"targets\"].to(device)\n",
        "        outputs = model(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask\n",
        "        )\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        correct_predictions += torch.sum(preds == targets)\n",
        "        losses.append(loss.item())\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To reproduce the training procedure from the BERT paper, we'll use the [AdamW](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adamw) optimizer provided by Hugging Face. It corrects weight decay, so it's similar to the original paper. We'll also use a linear scheduler with no warmup steps:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh",
        "colab_type": "text"
      },
      "source": [
        "Using those two, we can write our training loop. We'll also store the training history:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBQabTAZ2B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "\n",
        "%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF--CY3wacp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CQvf1rTe1p8",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "So how good is our model on predicting sentiment? Let’s start by calculating the accuracy on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZdC_na6d2Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGTUp8ird6U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(targets)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values\n",
        "\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0MuFQs63bLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(model,test_data_loader)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INvXTR4ReEvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_name, columns=class_name)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx0U7oNsnZ3A",
        "colab_type": "text"
      },
      "source": [
        "This confirms that our model is having difficulty classifying neutral reviews. It mistakes those for negative and positive at a roughly equal frequency.\n",
        "\n",
        "That's a good overview of the performance of our model. But let's have a look at an example from our test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD5VSg5QVovQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 5\n",
        "review_text = y_review_texts[idx]\n",
        "true_sentiment = y_test[idx]\n",
        "pred_df = pd.DataFrame({\n",
        "  'class_names': class_name,\n",
        "  'values': y_pred_probs[idx]\n",
        "})\n",
        "\n",
        "print(\"\\n\".join(wrap(review_text)))\n",
        "print()\n",
        "print(f'True sentiment: {class_name[true_sentiment]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7hj_IZFnn2X",
        "colab_type": "text"
      },
      "source": [
        "Now we can look at the confidence of each sentiment of our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tXmDg4jeiXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
        "plt.ylabel('sentiment')\n",
        "plt.xlabel('probability')\n",
        "plt.xlim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaZziNOi1Y_0",
        "colab_type": "text"
      },
      "source": [
        "Uncoment this code to download the pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0W6I7xK1ZzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gdown --id 1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA\n",
        "\n",
        "# model = SentimentClassifier(len(class_names))\n",
        "# model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "# model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAWc_4VSenmR",
        "colab_type": "text"
      },
      "source": [
        "# Predicting on Raw Text\n",
        "Let’s use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttY86rCVotjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_text = \"When was I last outside? I am stuck at home for 2 months\"\n",
        "\n",
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n",
        "\n",
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'Sentiment  : {class_name[prediction]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OraTifxGy1vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33cYQcH1ySr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "baa04bd3-4276-4494-f1a5-7a825f569f89"
      },
      "source": [
        "import jovian\n",
        "\n",
        "# Project name used for jovian.commit\n",
        "project_name = 'Sentiment Analysis with BERT'\n",
        "jovian.commit(project=project_name, outputs=['Sentiment Analysis with BERT'], environment=None)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m[jovian] Error: Failed to detect Jupyter notebook or Python script. Skipping..\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WoGjnNdzINA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}